  <!------------------------------------------------------------------------------DOCUMENT CONFIGURATION----------------------------------------------------------------------------->
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="From Pixels to Wireframes: 3D Reconstruction via CLIP-Based Sketch Abstraction.">
  <meta name="keywords" content="3D Sketches, Wireframes, 3D Vision, CLIP, CLIPasso">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>From Pixels to Wireframes: 3D Reconstruction via CLIP-Based Sketch Abstraction</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!--<script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>-->
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>
  
<script type="text/javascript"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
  
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<!------------------------------------------------------------------------------NAVIGATION BAR BUTTONS----------------------------------------------------------------------------->


<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://vilab.epfl.ch/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>
    </div>

  </div>
</nav>

<!------------------------------------------------------------------------------AUTHORS SECTION----------------------------------------------------------------------------->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">From Pixels to Wireframes: 3D Reconstruction via CLIP-Based Sketch Abstraction</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://tarhanefe.github.io/">Efe Tarhan</a>,</span>
            <span class="author-block">
              <a href="https://people.epfl.ch/filip.mikoviny/?lang=en">Filip Mikovíny</a>,</span>
            <span class="author-block">
              <a href="https://people.epfl.ch/eylul.ipci?lang=en">Eylül Ipçi</a>,</span>
            <span class="author-block">
              <a href="https://people.epfl.ch/alberts.reisons">Alberts Reisons</a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Swiss Federal Institute of Technology Lausanne (EPFL)</span>
          </div>
  
<!------------------------------------------------------------------------------LINKS UNDER AUTHORS----------------------------------------------------------------------------->

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/tarhanefe/clipasso3d"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://youtu.be/Qa8kh6aMo-8"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/tarhanefe/CLIPasso3DWebsite"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Website</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!------------------------------------------------------------------------------TEASER GIF----------------------------------------------------------------------------->


<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div style="display: flex; justify-content: center; gap: 1rem;">
        <img src="./static/gifs/rose_gt.gif" alt="Ground Truth Rose" style="max-width: 100%; height: auto;">
        <img src="./static/gifs/rose_20.gif" alt="3D Abstract Sketch of Rose" style="max-width: 100%; height: auto;">
      </div>
    </div>
  </div>
</section>


<!------------------------------------------------------------------------------ABSTRACT----------------------------------------------------------------------------->


<section class="section hero is-light">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Sketch abstraction allows objects to be represented with minimal yet meaningful visual elements. 
            While recent methods enable machines to generate 2D sketches from images, they remain limited to flat representations. 
            In this project, we extend sketch abstraction to 3D by optimizing Bézier curves on reconstructed surfaces, using CLIP-based losses to produce semantically meaningful and view-consistent wireframe sketches.
          </p>
        </div>

      </div>
    </div>

<!------------------------------------------------------------------------------CONTENT TABLE----------------------------------------------------------------------------->

    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">

        <h2 class="title is-3">Overview</h2>
        <div class="tile is-ancestor is-centered" style="vertical-align: middle;">
          <div class="tile is-parent">
            <a href="#intro" class="tile is-child box">
              <p class="subtitle"><font size="-1">Introduction</font></p>
            </a>
          </div>

          <div class="tile is-parent">
            <a href="#related-work" class="tile is-child box">
              <p class="subtitle"><font size="-1">Related Works</font></p>
            </a>
          </div>

          <div class="tile is-parent">
            <a href="#method" class="tile is-child box">
              <p class="subtitle"><font size="-1">Methodology</font></p>
            </a>
          </div>

          <div class="tile is-parent">
            <a href="#exp" class="tile is-child box">
              <p class="subtitle"><font size="-1">Experiments</font></p>
            </a>
          </div>

          <div class="tile is-parent">
            <a href="#conclusion" class="tile is-child box">
              <p class="subtitle"><font size="-1">Conclusion and Limitations</font></p>
            </a>
          </div>
        </div>

      </div>
    </div>
    <!--/ Abstract. -->


  <!------------------------------------------------------------------------------PROJECT VIDEO---------------------------------------------------------------------------->

    <!-- Paper video.
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="project-video">
          <iframe width="560" height="315" src="https://www.youtube.com/embed/Qa8kh6aMo-8?si=Clq5caeAaY32thoL" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    Paper video. -->
  </div>
</section>



  <!------------------------------------------------------------------------------INTRODUCTION----------------------------------------------------------------------------->

<section class="section">
  <div class="container is-max-desktop">
    <!-- Introduction. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3" id="intro">I. Introduction</h2>
        <div class="content has-text-justified">
          <p>
            Sketching is a powerful form of abstraction that captures the essence of objects using minimal visual elements. 
            This process requires selecting key visual features that convey meaning while omitting others, which demands a level of semantic understanding that is more difficult for machines than for humans. 
            Recent advances, such as CLIPasso \cite{vinker2022clipasso}, have enabled machines to automatically convert images into recognizable abstract sketches using semantic information utilizing SOTA image-text representation method Contrastive Language–Image Pretraining (CLIP) \cite{CLIP}. 
            However, these methods are currently limited to two dimensions. 
          </p>
          <p>
            In this project, we try to extend this idea to 3D: can machines generate 3D sketches that preserve both semantic and geometric information of an object? 
            Addressing this question could open up new possibilities for visual communication and rapid prototyping, paving the way for innovative tools in 3D design and visualization.
          </p>
        </div>
      </div>
    </div>
    <!--/ Introduction. -->
  </div>
</section>



<!------------------------------------------------------------------------------RELATED WORK----------------------------------------------------------------------------->







  
<!------------------------------------------------------------------------------METHODOLOGY----------------------------------------------------------------------------->

<section class="section">
  <div class="container is-max-desktop">
    <!-- Method. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3" id="method">III. Methodology</h2>
        <div class="content has-text-justified">
          <p>
            In this section, we present the methodology utilized for this paper. We first discuss the environment setup,
            after which we detail how the predator and prey agents are created. Finally, we talk about how the agents are optimized.
          </p>
          <p>
            We create a 3D environment using the Unity game development engine <a href="https://unity.com/">[3]</a>. The selection of Unity as the engine
            for creating the environment instead of a different simulator is motivated by several key factors. Mainly, Unity's ML-Agents
            package <a href="https://arxiv.org/abs/1809.02627">[4]</a> offers support for the OpenAI Gym framework
            <a href="https://arxiv.org/abs/1809.02627">[5]</a>, which is widely used in
            reinforcement learning research. This way, Unity enables interaction between the environment and the learning algorithms,
            allowing for efficient experimentation and evaluation of predator-prey agents.
          </p>
          <p>
            Moreover, the engine offers a wide range of built-in tools, such as physics simulations, ray tracing, and collision.
            Finally, Unity provides a user-friendly and intuitive development environment, making it accessible to researchers with
             varying levels of expertise.
          </p>
        </div>
        <!-- Creating environments. -->
<!------------------------------------------------------------------------------SPHERICAL GAUSSIANS----------------------------------------------------------------------------->
        
<h3 class="title is-4">III-A. 3D Differentiable Rasterization with Spherical Gaussians</h3>
<div class="content has-text-justified">
  <p>
    To represent 3D sketches in a differentiable manner, we model 3D Bézier curves using spherical Gaussians (SGs) sampled along each curve’s path. This design allows efficient rasterization of the sketches into 2D images for training. Unlike CLIPasso’s discrete 2D rasterization, our approach supports backpropagation in 3D space and enables full differentiability with respect to the control points. Inspired by recent advances in Gaussian Splatting, we represent Bézier curves as sequences of Gaussians, each defined by a center and a fixed thickness, that can be projected onto 2D views using differentiable camera models.
  </p>

  <div class="columns is-centered">
    <div class="column is-three-quarters">
      <div align="center" class="box">
        <img src="static/website_assets/image_2.png" alt="3D Bezier curves are used for representing 3D sketches of objects.">
        <h5 class="subtitle has-text-centered">
          <font size="-0.7">
            <span style="font-weight:normal">
              3D Bézier curves are used for representing 3D sketches of objects.
            </span>
          </font>
        </h5>
      </div>
    </div>
  </div>

  <p>
    Each spherical Gaussian is defined as:
  </p>
  <pre><code>
φ(x; c, r) = exp(-||x - c||² / (2r²))
  </code></pre>
  <p>
    where <code>c ∈ ℝ³</code> is the Gaussian center along the curve, and <code>r</code> defines its thickness. To sample a Bézier curve of length <code>L</code> with overlap ratio <code>αₒ</code>, we define the step size <code>d</code> and number of samples <code>N</code> as:
  </p>
  <pre><code>
d = r * αₒ
N = ceil(L / d)
  </code></pre>
  <p>
    Let the Bézier curve <code>B</code> have control points <code>p₀, ..., p_M ∈ ℝ³</code>. The Gaussian means <code>cₙ</code> along the curve are sampled using the Bézier basis:
  </p>
  <pre><code>
cₙ,B = Σ₍i=0₎^M γᵢ * (1 - n/N)^(M-i) * (n/N)^i * pᵢ
  </code></pre>
  <p>
    where <code>γᵢ</code> are the Bernstein basis coefficients. This formulation ensures that the Gaussians’ positions are differentiable with respect to the control points of the curve.
  </p>

  <div class="columns is-centered">
    <div class="column is-three-quarters">
      <div align="center" class="box">
        <img src="static/website_assets/image_3.png" alt="Spherical Gaussians are utilized for differentiable rasterization of the 3D sketches.">
        <h5 class="subtitle has-text-centered">
          <font size="-0.7">
            <span style="font-weight:normal">
              Spherical Gaussians are utilized for differentiable rasterization of the 3D sketches.
            </span>
          </font>
        </h5>
      </div>
    </div>
  </div>

  <p>
    After constructing the Gaussians, we render them through a differentiable rasterizer. This process projects the 3D centers into 2D using both intrinsic (<code>In</code>) and extrinsic (<code>Ex</code>) camera matrices. The rasterizer outputs a 2D grayscale image <code>V ∈ ℝ^{W × H}</code> where:
  </p>
  <pre><code>
V = T(c, r, In, Ex, W, H)
  </code></pre>
  <p>
    Each pixel value <code>Vₙ₁,ₙ₂</code> depends on the projection of all Gaussian samples from the Bézier curves. Since the entire pipeline—curve sampling, projection, and rasterization—is differentiable, gradients can be propagated from the image space back to the curve’s control points. This capability is essential for learning sketches from image-level supervision.
  </p>

</div>
        <!--/ Creating environments. -->
<!------------------------------------------------------------------------------TRAINING----------------------------------------------------------------------------->
        <h3 class="title is-4">III-C. Model Training</h3>
        <div class="content has-text-justified">
          <p>
            The training phase aims to optimize a set of 3D Bézier curves such that their 2D projections resemble real object images when viewed from different camera angles. This is achieved through an iterative loop involving projection, perceptual comparison, and gradient-based refinement. By leveraging CLIP embeddings as a supervisory signal, the model learns to align the rendered sketch views with the semantics of real RGB views. The training continues until convergence, producing a geometry-aware sketch representation that is both visually and semantically faithful.
          </p>
            <div class="columns is-centered">
            <div class="column is-three-quarters">
              <div align="center" class="box">
                <img src="static/website_assets/method_1.gif" alt="Rasterization of images using camera matrix from the constructred 3D sketch.">
                <h5 class="subtitle has-text-centered">
                  <font size="-0.7">
                    <span style="font-weight:normal">Rasterization of images using camera matrix from the constructred 3D sketch.</span>
                  </font>
                </h5>
              </div>
            </div>
          </div>
          
          <p>
In each training iteration, the current 3D Bézier sketch is projected into 2D using the known camera intrinsics and extrinsics. This rasterization step generates a view-dependent binary sketch image that mimics how the 3D curves would appear from that specific viewpoint.          
          </p>
          
          <div class="columns is-centered">
            <div class="column is-three-quarters">
              <div align="center" class="box">
                <img src="static/website_assets/method_2.gif" alt="Obtaining the CLIP Loss between the RGB images of the views and sampled sketch views.">
                <h5 class="subtitle has-text-centered">
                  <font size="-0.7">
                    <span style="font-weight:normal">Obtaining the CLIP Loss between the RGB images of the views and sampled sketch views.</span>
                  </font>
                </h5>
              </div>
            </div>
          </div>

          <p>
  The projected sketch view is then compared to the corresponding RGB image of the same view. Both are encoded using CLIP’s vision-language model, and a cosine similarity loss is computed to quantify their perceptual alignment in the embedding space.
          </p>

          <div class="columns is-centered">
            <div class="column is-three-quarters">
              <div align="center" class="box">
                <img src="static/website_assets/method_3.gif" alt="Optimizing the control points using the backpropagated loss.">
                <h5 class="subtitle has-text-centered">
                  <font size="-0.7">
                    <span style="font-weight:normal">Optimizing the control points using the backpropagated loss.</span>
                  </font>
                </h5>
              </div>
            </div>
          </div>

          <p>
  The CLIP loss is backpropagated through the differentiable projection and rendering pipeline to adjust the 3D control points of the Bézier curves. This step ensures that the curves evolve to better match the visual content of the reference images.
          </p>

          <div class="columns is-centered">
            <div class="column is-three-quarters">
              <div align="center" class="box">
                <img src="static/website_assets/method_4.gif" alt="Training the model until loss converges.">
                <h5 class="subtitle has-text-centered">
                  <font size="-0.7">
                    <span style="font-weight:normal">Training the model until loss converges.</span>
                  </font>
                </h5>
              </div>
            </div>
          </div>

           <p>
  This process is repeated iteratively for all views in the dataset. Over time, the loss steadily decreases as the curves converge to a semantically accurate and geometrically coherent representation of the object across all viewpoints.
          </p>

          
        </div>
        <!--/ Creating environments. -->
  <!------------------------------------------------------------------------------TRAINING----------------------------------------------------------------------------->

      </div>
    </div>
  </div>
</section>






<!------------------------------------------------------------------------------EXPERIMENTS----------------------------------------------------------------------------->

  



<!------------------------------------------------------------------------------CONCLUSION & LIMITATIONS---------------------------------------------------------------->

  


  
<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <!-- Visual Effects. -->
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Visual Effects</h2>
          <p>
            Using <i>nerfies</i> you can create fun visual effects. This Dolly zoom effect
            would be impossible without nerfies since it would require going through a wall.
          </p>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/dollyzoom-stacked.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ Visual Effects. -->

      <!-- Matting. -->
      <div class="column">
        <h2 class="title is-3">Matting</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              As a byproduct of our method, we can also solve the matting problem by ignoring
              samples that fall outside of a bounding box during rendering.
            </p>
            <video id="matting-video" controls playsinline height="100%">
              <source src="./static/videos/matting.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
    </div>
    <!--/ Matting. -->

    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Animation</h2>

        <!-- Interpolating. -->
        <h3 class="title is-4">Interpolating states</h3>
        <div class="content has-text-justified">
          <p>
            We can also animate the scene by interpolating the deformation latent codes of two input
            frames. Use the slider here to linearly interpolate between the left frame and the right
            frame.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_start.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>Start Frame</p>
          </div>
          <div class="column interpolation-video-column">
            <div id="interpolation-image-wrapper">
              Loading...
            </div>
            <input class="slider is-fullwidth is-large is-info"
                   id="interpolation-slider"
                   step="1" min="0" max="100" value="0" type="range">
          </div>
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_end.jpg"
                 class="interpolation-image"
                 alt="Interpolation end reference image."/>
            <p class="is-bold">End Frame</p>
          </div>
        </div>
        <br/>
        <!--/ Interpolating. -->

        <!-- Re-rendering. -->
        <h3 class="title is-4">Re-rendering the input video</h3>
        <div class="content has-text-justified">
          <p>
            Using <span class="dnerf">Nerfies</span>, you can re-render a video from a novel
            viewpoint such as a stabilized camera by playing back the training deformations.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="75%">
            <source src="./static/videos/replay.mp4"
                    type="video/mp4">
          </video>
        </div>
        <!--/ Re-rendering. -->

      </div>
    </div>
    <!--/ Animation. -->


    <!-- Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was introduced around the same time as ours.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.
          </p>
          <p>
            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
            both use deformation fields to model non-rigid scenes.
          </p>
          <p>
            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
          </p>
          <p>
            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
          </p>
        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
